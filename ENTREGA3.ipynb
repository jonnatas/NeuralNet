{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/jonnatas/anaconda3/envs/tcc/lib/python3.6/site-packages/deap/tools/_hypervolume/pyhv.py:33: ImportWarning: Falling back to the python version of hypervolume module. Expect this to be very slow.\n",
      "  \"module. Expect this to be very slow.\", ImportWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras import optimizers\n",
    "\n",
    "from deap import creator, base, tools, algorithms\n",
    "from scoop import futures\n",
    "import random\n",
    "import numpy\n",
    "from scipy import interpolate\n",
    "import matplotlib.pyplot as plt\n",
    "numpy.random.seed(7)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leitura e tratamento dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfData = numpy.loadtxt(\"diabetes.csv\", delimiter=\",\")\n",
    "xdataset = dfData[:, 0:8]\n",
    "ydataset = dfData[:, 8]\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_scaler = scaler.fit_transform(xdataset)\n",
    "labels = ['gravida',\n",
    "         'glicose plamática',\n",
    "         'perssão arterial diastólica',\n",
    "         'dobra da pele tríceps',\n",
    "         'insulina sérica',\n",
    "         'IMC',\n",
    "         'Função pedigree',\n",
    "         'Idade']\n",
    "allFeatures = pd.DataFrame(X_scaler,columns=labels)\n",
    "allClasses = pd.DataFrame(ydataset,columns=['Diabetes'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separando os dados em treino, teste e validação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Form training, test, and validation sets\n",
    "X_trainAndTest, X_validation, y_trainAndTest, y_validation = train_test_split(\n",
    "    allFeatures, allClasses, test_size=0.20, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_trainAndTest, y_trainAndTest, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Função de Treino, serve para obter a acuracia para a utilizada na função-objetivo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Função de ativação 'sigmoid';\n",
    "* Topologia: E - H - 1;\n",
    "* E = número de entradas entradas, definidas pelo AG;\n",
    "* H = (E * 2) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTrainMLP(X_trainOhFeatures, y_train, X_testOhFeatures, y_test):\n",
    "    clf = MLPClassifier(solver='lbfgs', max_iter=1000, activation='logistic', alpha=1e-5,\n",
    "                        hidden_layer_sizes=(len(X_trainOhFeatures.columns)*2+1,), random_state=1)\n",
    "    clf.fit(X_trainOhFeatures, y_train)\n",
    "    predictions = clf.predict(X_testOhFeatures)\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTrainRNA(X_trainOhFeatures, y_train, X_testOhFeatures, y_test):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(17,use_bias=True, input_dim=len(X_trainOhFeatures.columns), activation='sigmoid'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    Adamax = optimizers.Adamax(lr=0.002, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=Adamax, metrics=['accuracy'])\n",
    "    model.fit(X_trainOhFeatures, y_train, epochs=10, shuffle=True)\n",
    "\n",
    "    predictions=model.predict(X_testOhFeatures)\n",
    "    yPred = np.array([round(x[0]) for x in predictions])\n",
    "    accuracy = accuracy_score(y_test, yPred)\n",
    "    print('Accuracy : '+str(accuracy))\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature subset fitness function\n",
    "def getFitness(individual, X_train, X_test, y_train, y_test):\n",
    "\n",
    "    # Colocar as features de treinamento, na lista para manipulação.\n",
    "    cols = [index for index in range(len(individual)) if individual[index] == 0]\n",
    "    X_trainParsed = X_train.drop(X_train.columns[cols], axis=1)\n",
    "    X_trainOhFeatures = pd.get_dummies(X_trainParsed)\n",
    "    X_testParsed = X_test.drop(X_test.columns[cols], axis=1)\n",
    "    X_testOhFeatures = pd.get_dummies(X_testParsed)\n",
    "\n",
    "    # Remover as Features que não estão no conjunto de treinamento\n",
    "    sharedFeatures = set(X_trainOhFeatures.columns) & set(X_testOhFeatures.columns)\n",
    "    removeFromTrain = set(X_trainOhFeatures.columns) - sharedFeatures\n",
    "    removeFromTest = set(X_testOhFeatures.columns) - sharedFeatures\n",
    "    X_trainOhFeatures = X_trainOhFeatures.drop(list(removeFromTrain), axis=1)\n",
    "    X_testOhFeatures = X_testOhFeatures.drop(list(removeFromTest), axis=1)\n",
    "\n",
    "    # Chamando a rede neural\n",
    "    accuracy = getTrainMLP(X_trainOhFeatures, y_train, X_testOhFeatures, y_test)\n",
    "\n",
    "    # Return calculated accuracy as fitness\n",
    "    return (accuracy,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getHof(numPop=100, numGen=10, cxpb=0.5, mutpb=0.2):\n",
    "\n",
    "    pop = toolbox.population(n=numPop)\n",
    "    hof = tools.HallOfFame(numPop * numGen)\n",
    "    stats = tools.Statistics(lambda ind: ind.fitness.values)\n",
    "    stats.register(\"Média\", numpy.mean)\n",
    "    stats.register(\"Des. Padr.\", numpy.std)\n",
    "    stats.register(\"Mínimo\", numpy.min)\n",
    "    stats.register(\"Máximo\", numpy.max)\n",
    "\n",
    "    # Rodando o algoritmo genético\n",
    "    pop, log = algorithms.eaSimple(pop, toolbox, cxpb, mutpb, ngen=numGen, \n",
    "                                       stats=stats, halloffame=hof, verbose=True)\n",
    "    # Return the hall of fame\n",
    "    return hof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMetrics(hof):\n",
    "\n",
    "    # Pegando a lista com as melhores features.\n",
    "    percentileList = [i / (len(hof) - 1) for i in range(len(hof))]\n",
    "\n",
    "    # Separando as métricas de teste, validação.\n",
    "    testAccuracyList = []\n",
    "    validationAccuracyList = []\n",
    "    individualList = []\n",
    "    \n",
    "    for individual in hof:\n",
    "        testAccuracy = individual.fitness.values\n",
    "        validationAccuracy = getFitness(individual, X_trainAndTest, X_validation, y_trainAndTest, y_validation)\n",
    "        testAccuracyList.append(testAccuracy[0])\n",
    "        validationAccuracyList.append(validationAccuracy[0])\n",
    "        individualList.append(individual)\n",
    "    testAccuracyList.reverse()\n",
    "    validationAccuracyList.reverse()\n",
    "    \n",
    "    return testAccuracyList, validationAccuracyList, individualList, percentileList"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rodando a rede para comparar a acurácia antes da seleção das features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jonnatas/anaconda3/envs/tcc/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:912: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Precisão de teste com todas as features: \t0.658536585366\n",
      "Precisão de validação com todas as features: \t0.662337662338\n",
      "\n",
      "Features: 8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['gravida', 'glicose plamática', 'perssão arterial diastólica',\n",
       "       'dobra da pele tríceps', 'insulina sérica', 'IMC', 'Função pedigree',\n",
       "       'Idade'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "individual = [1 for i in range(len(allFeatures.columns))]\n",
    "testAccuracy = getFitness(individual, X_train, X_test, y_train, y_test)\n",
    "validationAccuracy = getFitness(individual, X_trainAndTest, X_validation, y_trainAndTest, y_validation)\n",
    "print('\\nPrecisão de teste com todas as features: \\t' + str(testAccuracy[0]))\n",
    "print('Precisão de validação com todas as features: \\t' + str(validationAccuracy[0]) + '\\n')\n",
    "print('Features: '+str(len(allFeatures.columns)))\n",
    "allFeatures.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algoritmo genético, para selecionar as features.\n",
    "\n",
    "## Crossover\n",
    "* cxOnePoint, cruza os dados de dois pontos, taxa de 0.2\n",
    "\n",
    "## Mutação\n",
    "* mutFlipBit, taxa de mutação com 0.05.\n",
    "\n",
    "## Seleção\n",
    "* selTournament, Utiliza a seleção por torneio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria uma classe para o individuo.\n",
    "creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,))\n",
    "creator.create(\"Individual\", list, fitness=creator.FitnessMax)\n",
    "\n",
    "# Cria um o AG com um Toolbox.\n",
    "toolbox = base.Toolbox()\n",
    "toolbox.register(\"attr_bool\", random.randint, 0, 1)\n",
    "toolbox.register(\"individual\", tools.initRepeat, creator.Individual, \n",
    "                 toolbox.attr_bool, len(allFeatures.columns))\n",
    "toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "\n",
    "# Configurando o AG\n",
    "toolbox.register(\"evaluate\", getFitness, X_train=X_train, X_test=X_test, y_train=y_train, y_test=y_test)\n",
    "toolbox.register(\"mate\", tools.cxOnePoint)\n",
    "toolbox.register(\"mutate\", tools.mutFlipBit, indpb=0.05)\n",
    "toolbox.register(\"select\", tools.selTournament, tournsize=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jonnatas/anaconda3/envs/tcc/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:912: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No objects to concatenate",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-0a0f2d890d5e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhof\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetHof\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumPop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumGen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcxpb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmutpb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtestAccuracyList\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidationAccuracyList\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindividualList\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpercentileList\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetMetrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhof\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-f96db7e7dae1>\u001b[0m in \u001b[0;36mgetHof\u001b[0;34m(numPop, numGen, cxpb, mutpb)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m# Rodando o algoritmo genético\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     pop, log = algorithms.eaSimple(pop, toolbox, cxpb, mutpb, ngen=numGen, \n\u001b[0;32m---> 13\u001b[0;31m                                        stats=stats, halloffame=hof, verbose=True)\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0;31m# Return the hall of fame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mhof\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tcc/lib/python3.6/site-packages/deap/algorithms.py\u001b[0m in \u001b[0;36meaSimple\u001b[0;34m(population, toolbox, cxpb, mutpb, ngen, stats, halloffame, verbose)\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0minvalid_ind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mind\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mind\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpopulation\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfitness\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m     \u001b[0mfitnesses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtoolbox\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoolbox\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minvalid_ind\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minvalid_ind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfitnesses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m         \u001b[0mind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfitness\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-12c21f9705a1>\u001b[0m in \u001b[0;36mgetFitness\u001b[0;34m(individual, X_train, X_test, y_train, y_test)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mcols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindividual\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mindividual\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mX_trainParsed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mX_trainOhFeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_dummies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_trainParsed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mX_testParsed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mX_testOhFeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_dummies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_testParsed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tcc/lib/python3.6/site-packages/pandas/core/reshape/reshape.py\u001b[0m in \u001b[0;36mget_dummies\u001b[0;34m(data, prefix, prefix_sep, dummy_na, columns, sparse, drop_first)\u001b[0m\n\u001b[1;32m   1210\u001b[0m                                     drop_first=drop_first)\n\u001b[1;32m   1211\u001b[0m             \u001b[0mwith_dummies\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdummy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1212\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwith_dummies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1213\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1214\u001b[0m         result = _get_dummies_1d(data, prefix, prefix_sep, dummy_na,\n",
      "\u001b[0;32m~/anaconda3/envs/tcc/lib/python3.6/site-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, join_axes, ignore_index, keys, levels, names, verify_integrity, copy)\u001b[0m\n\u001b[1;32m    210\u001b[0m                        \u001b[0mkeys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m                        \u001b[0mverify_integrity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverify_integrity\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m                        copy=copy)\n\u001b[0m\u001b[1;32m    213\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tcc/lib/python3.6/site-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, objs, axis, join, join_axes, keys, levels, names, ignore_index, verify_integrity, copy)\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'No objects to concatenate'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkeys\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: No objects to concatenate"
     ]
    }
   ],
   "source": [
    "hof = getHof(numPop=100, numGen=10, cxpb=0.5, mutpb=0.2)\n",
    "testAccuracyList, validationAccuracyList, individualList, percentileList = getMetrics(hof)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Melhores dados relacionados as Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxValAccSubsetIndicies = [index for index in range(len(validationAccuracyList)) if validationAccuracyList[index] == max(validationAccuracyList)]\n",
    "maxValIndividuals = [individualList[index] for index in maxValAccSubsetIndicies]\n",
    "maxValSubsets = [[list(allFeatures)[index] for index in range(len(individual)) if individual[index] == 1] for individual in maxValIndividuals]\n",
    "print('\\n---Seleção de features---\\n')\n",
    "\n",
    "for index in range(len(maxValAccSubsetIndicies)):\n",
    "    print('Precisão de treino: \\t\\t' + str(percentileList[maxValAccSubsetIndicies[index]]))\n",
    "    print('Precisão de validação: \\t\\t' + str(validationAccuracyList[maxValAccSubsetIndicies[index]]))\n",
    "    print('Individuo: \\t\\t\\t' + str(maxValIndividuals[index]))\n",
    "    print('Total de Features utilizadas: \\t' + str(len(maxValSubsets[index])))\n",
    "    print('Features: \\t\\t\\t' + str(maxValSubsets[index]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gráfico de comparação\n",
    "### Considerando os piores conjuntos, até os melhores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tck = interpolate.splrep(percentileList, validationAccuracyList, s=5.0)\n",
    "ynew = interpolate.splev(percentileList, tck)\n",
    "\n",
    "e = plt.figure(1)\n",
    "plt.plot(percentileList, validationAccuracyList, marker='o', color='r')\n",
    "plt.plot(percentileList, ynew, color='b')\n",
    "plt.title('Validação Set Classification Accuracy vs. \\n Continuum with Cubic-Spline Interpolation')\n",
    "plt.xlabel('Population Ordered By Increasing Test Set Accuracy')\n",
    "plt.ylabel('Precisão do dados de validação')\n",
    "e.show()\n",
    "\n",
    "g = plt.figure(2)\n",
    "plt.scatter(percentileList, testAccuracyList)\n",
    "plt.title('Classificação dos dados de Teste vs. Continuum')\n",
    "plt.xlabel('Population Ordered By Increasing Test Set Accuracy')\n",
    "plt.ylabel('Precisão do dados de testes')\n",
    "g.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
